{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnzdoeY7Z7fC"
      },
      "source": [
        "# CHATBOT RAG\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iLBUjsfaOPz"
      },
      "source": [
        "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\n",
        "\n",
        "\n",
        "llx-OmKjJeRUzpUUJKnvXaMlXeYzYDwqo1YOwQ5ie9v2nSaCwYqr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6F_H-mqlopR"
      },
      "source": [
        "# Chatbot Skrips\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_F4lXZDDWmB"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoHAw5U9Ez3D",
        "outputId": "d6d3947e-5335-4b5a-f821-e6e1e1305ad6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -qU pypdf langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaNFUxGjGcn0",
        "outputId": "3e314af1-6de8-4ee0-aad8-3680d2b05298"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzacHTgTE1bc",
        "outputId": "95cea7e4-6bcd-434e-c6cd-27201e21862a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "51\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "file_path = \"./Pedoman_Skripsi.pdf\"\n",
        "loader = PyPDFLoader(file_path)\n",
        "\n",
        "docs = loader.load()\n",
        "\n",
        "print(len(docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peqHBArTFpGq",
        "outputId": "4cbe2372-c8dd-4701-e12f-7ac21bfdc7ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JURUSAN TEKNIK INFORMATIKA DAN KOMPUTER \n",
            "| PNJ  \n",
            " \n",
            "Pedoman Skripsi \n",
            "Mahasiswa \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "D\n",
            "{'producer': 'Microsoft® Word 2016', 'creator': 'Microsoft® Word 2016', 'creationdate': '2024-02-21T21:57:40+07:00', 'author': 'jURUSAN TEKNIK INFORMATIKA DAN KOMPUTER | PNJ', 'moddate': '2024-12-19T13:50:46+07:00', 'source': './Pedoman_Skripsi.pdf', 'total_pages': 51, 'page': 0, 'page_label': '1'}\n"
          ]
        }
      ],
      "source": [
        "print(docs[0].page_content[0:100])\n",
        "print(docs[0].metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDASW2N-F6H1",
        "outputId": "57638caa-9b4a-45b7-b7f6-c93f508276f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/121.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/415.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.4/415.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F--__fPrF7pu",
        "outputId": "2f8208d7-0288-4a4c-cd7f-fcbcd1ec60c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(model=\"llama3-8b-8192\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9f1kksZGNPF",
        "outputId": "dcc69424-86cf-48c0-b995-be3683ad7aaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.3 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -qU langchain-pinecone pinecone-notebooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WCPX6bYnG8ge",
        "outputId": "761de839-f3cc-44ff-a8af-244c4ed6f33e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.42 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.3.43)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.61.1)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (0.3.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (2.10.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.42->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain_openai) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain_openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.42->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.42->langchain_openai) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.3.0)\n",
            "Downloading langchain_openai-0.3.8-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain_openai\n",
            "Successfully installed langchain_openai-0.3.8 tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62Dkswe-G3Xi",
        "outputId": "4de51324-cd24-4b30-f9d0-8af6bcdb084c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter API key for OpenAI: ··········\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ce8ySc0eIKYQ"
      },
      "outputs": [],
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "from pinecone import Pinecone\n",
        "\n",
        "pc = Pinecone(api_key=\"pcsk_77dQAK_QExzGnian2Q2VhBhhLA6dDDGd4dCQQyBchTXeDYMLBRKJbe81ynnQaVyZekSiAk\")\n",
        "index = pc.Index(\"rag\")\n",
        "\n",
        "vector_store = PineconeVectorStore(embedding=embeddings, index=index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wSAyuSHvKiaZ",
        "outputId": "43ca981f-4d58-488f-8675-06b42c438ca8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.3.6-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.43)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.18-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.55-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (0.3.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (2.10.6)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.3.6-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.18-py3-none-any.whl (39 kB)\n",
            "Downloading langgraph_prebuilt-0.1.2-py3-none-any.whl (24 kB)\n",
            "Downloading langgraph_sdk-0.1.55-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.3.6 langgraph-checkpoint-2.0.18 langgraph-prebuilt-0.1.2 langgraph-sdk-0.1.55\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "!pip install langgraph\n",
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.documents import Document\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langgraph.graph import START, StateGraph\n",
        "from typing_extensions import List, TypedDict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0crV2EfcKfHB"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "all_splits = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4A1DKYvwK6NB"
      },
      "outputs": [],
      "source": [
        "# Index chunks\n",
        "_ = vector_store.add_documents(documents=all_splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae9mn7p9l-_K"
      },
      "source": [
        "## RAG simple step retrieve process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyeSUirQlxa3"
      },
      "outputs": [],
      "source": [
        "# Define prompt for question-answering\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "\n",
        "# Define state for application\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    context: List[Document]\n",
        "    answer: str\n",
        "\n",
        "\n",
        "# Define application steps\n",
        "def retrieve(state: State):\n",
        "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
        "    return {\"context\": retrieved_docs}\n",
        "\n",
        "\n",
        "def generate(state: State):\n",
        "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
        "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
        "    response = llm.invoke(messages)\n",
        "    return {\"answer\": response.content}\n",
        "\n",
        "\n",
        "# Compile application and test\n",
        "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
        "graph_builder.add_edge(START, \"retrieve\")\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwEcBt6bl1v8",
        "outputId": "350f0fca-30ce-4837-dfbc-62c2db3ccaf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "According to the provided context, here is the answer to the question:\n",
            "\n",
            "APA aturan seminar proposal?\n",
            "\n",
            "Berikut aturan seminar proposal: Sidang Proposal Skripsi dilaksanakan dengan durasi 30 menit, terdiri dari 3 sesi, yaitu presentasi, tanya jawab, dan penutup.\n"
          ]
        }
      ],
      "source": [
        "response = graph.invoke({\"question\": \"apa aturan seminar proposal?\"})\n",
        "print(response[\"answer\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yW_AK_zmdvu"
      },
      "source": [
        "## Batas simple step retrieve process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvAWPnJ9msOT"
      },
      "source": [
        "# RAG dengan multi step process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VJaB0-1L0W6"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import MessagesState, StateGraph\n",
        "\n",
        "graph_builder = StateGraph(MessagesState)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vS1QahPL4Ck"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "\n",
        "@tool(response_format=\"content_and_artifact\")\n",
        "def retrieve(query: str):\n",
        "    \"\"\"Retrieve information related to a query.\"\"\"\n",
        "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
        "    serialized = \"\\n\\n\".join(\n",
        "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
        "        for doc in retrieved_docs\n",
        "    )\n",
        "    return serialized, retrieved_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSXPlePlMD6V"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import SystemMessage\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "\n",
        "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
        "def query_or_respond(state: MessagesState):\n",
        "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
        "    llm_with_tools = llm.bind_tools([retrieve])\n",
        "    response = llm_with_tools.invoke(state[\"messages\"])\n",
        "    # MessagesState appends messages to state instead of overwriting\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "# Step 2: Execute the retrieval.\n",
        "tools = ToolNode([retrieve])\n",
        "\n",
        "# Step 3: Generate a response using the retrieved content.\n",
        "def generate(state: MessagesState):\n",
        "    \"\"\"Generate answer.\"\"\"\n",
        "    # Get generated ToolMessages\n",
        "    recent_tool_messages = []\n",
        "    for message in reversed(state[\"messages\"]):\n",
        "        if message.type == \"tool\":\n",
        "            recent_tool_messages.append(message)\n",
        "        else:\n",
        "            break\n",
        "    tool_messages = recent_tool_messages[::-1]\n",
        "\n",
        "    # Format into prompt\n",
        "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
        "    system_message_content = (\n",
        "        \"You are an assistant for question-answering tasks. \"\n",
        "        \"Use the following pieces of retrieved context to answer \"\n",
        "        \"the question. If you don't know the answer, say that you \"\n",
        "        \"don't know. Keep the answer concise. \"\n",
        "        \"\\n\\n\"\n",
        "        f\"{docs_content}\"\n",
        "    )\n",
        "    conversation_messages = [\n",
        "        message\n",
        "        for message in state[\"messages\"]\n",
        "        if message.type in (\"human\", \"system\")\n",
        "        or (message.type == \"ai\" and not message.tool_calls)\n",
        "    ]\n",
        "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
        "\n",
        "    # Run\n",
        "    response = llm.invoke(prompt)\n",
        "    return {\"messages\": [response]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QA1pUO9rMjBv"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import END\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "graph_builder.add_node(query_or_respond)\n",
        "graph_builder.add_node(tools)\n",
        "graph_builder.add_node(generate)\n",
        "\n",
        "graph_builder.set_entry_point(\"query_or_respond\")\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"query_or_respond\",\n",
        "    tools_condition,\n",
        "    {END: END, \"tools\": \"tools\"},\n",
        ")\n",
        "graph_builder.add_edge(\"tools\", \"generate\")\n",
        "graph_builder.add_edge(\"generate\", END)\n",
        "\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWxAgbtvMr_o",
        "outputId": "4b577753-227d-4a41-a230-1c2ca3c62ed0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hello\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (call_0ktf)\n",
            " Call ID: call_0ktf\n",
            "  Args:\n",
            "    query: Hello\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'page': 0.0, 'page_label': '1', 'source': './Pedoman_Skripsi_2024-rev.pdf'}\n",
            "Content: JURUSAN TEKNIK INFORMATIKA DAN KOMPUTER \n",
            "| PNJ  \n",
            " \n",
            "Pedoman Skripsi \n",
            "Mahasiswa \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Daftar isi  \n",
            "JURUSAN TEKNIK INFORMATIKA DAN \n",
            "KOMPUTER POLITEKNIK NEGERI JAKARTA \n",
            "DEPOK 2024\n",
            "\n",
            "Source: {'page': 3.0, 'page_label': '4', 'source': './Pedoman_Skripsi_2024-rev.pdf'}\n",
            "Content: JURUSAN TEKNIK INFORMATIKA DAN KOMPUTER \n",
            "| PNJ\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello! I'm here to help answer your questions. What's your question about the given context?\n"
          ]
        }
      ],
      "source": [
        "input_message = \"Hello\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCUx5BUCM8lm",
        "outputId": "bdf4a8a8-72f6-4eaf-f6d1-1f32c258267f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Bagaimana format proposal skripsi?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (call_erjr)\n",
            " Call ID: call_erjr\n",
            "  Args:\n",
            "    query: Bagaimana format proposal skripsi\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'page': 1.0, 'page_label': '2', 'source': './Pedoman_Skripsi_2024-rev.pdf'}\n",
            "Content: 2.1 Syarat Pengajuan Proposal Skripsi....................................................................................... 9 \n",
            "2.2 Tata Cara Pengajuan Sidang Proposal Skripsi ...................................................................... 9 \n",
            "2.3 Tata Cara Sidang Proposal Skripsi ........................................................................................ 9 \n",
            "2.4 Format Susunan Proposal Skripsi ...................................................................................... 10 \n",
            "BAB III LAPORAN AKHIR SKRIPSI .................................................................................................. 12 \n",
            "3.1 Syarat Pendaftaran Sidang Akhir Skripsi............................................................................ 12 \n",
            "3.2 Prosedur Sidang Akhir Skripsi ............................................................................................ 12\n",
            "\n",
            "Source: {'page': 13.0, 'page_label': '14', 'source': './Pedoman_Skripsi_2024-rev.pdf'}\n",
            "Content: halaman proposal skripsi maksimal 20 (dua puluh) lembar, tidak termasuk lampiran. \n",
            "Bagian Awal \n",
            "1. Halaman Sampul (Program Studi TI : Teknik Informatika; Program Studi TMJ :  Teknik \n",
            "Multimedia dan Jaringan; Program Studi TMD : Teknik Multimedia Digital). \n",
            "2. Halaman Persetujuan Sidang Proposal oleh Dosen Pembimbing (dengan tanda tangan oleh \n",
            "Dosen Pembimbing. Apabila kelompok lebih dari 2 orang, tuliskan nama -nama anggota dan \n",
            "sub judul dengan pembimbing masing-masing). \n",
            "Bagian Isi \n",
            "Bagian Isi Proposal Skripsi terdiri dari: \n",
            "Bab I Pendahuluan \n",
            "1. Latar Belakang \n",
            "2. Perumusan Masalah \n",
            "3. Batasan Masalah \n",
            "4. Tujuan dan Manfaat \n",
            "5. Sistematika Penulisan (menguraikan susunan bab yang akan ada di laporan penelitian) \n",
            "Bab II Tinjauan Pustaka \n",
            "Bab III Perencanaan dan Realisasi Atau Rancang Bangun \n",
            "Uraikan secara rinci metode yang akan digunakan meliputi \n",
            "1. Rancangan penelitian \n",
            "2. Tahapan penelitian \n",
            "3. Objek penelitian\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Based on the provided content, the format of a proposal skripsi consists of:\n",
            "\n",
            "1. Bagian Awal:\n",
            "\t* Halaman Sampul (Program Studi)\n",
            "\t* Halaman Persetujuan Sidang Proposal oleh Dosen Pembimbing\n",
            "2. Bagian Isi:\n",
            "\t* Bab I Pendahuluan:\n",
            "\t\t+ Latar Belakang\n",
            "\t\t+ Perumusan Masalah\n",
            "\t\t+ Batasan Masalah\n",
            "\t\t+ Tujuan dan Manfaat\n",
            "\t\t+ Sistematika Penulisan\n",
            "\t* Bab II Tinjauan Pustaka\n",
            "\t* Bab III Perencanaan dan Realisasi Atau Rancang Bangun:\n",
            "\t\t+ Rancangan penelitian\n",
            "\t\t+ Tahapan penelitian\n",
            "\t\t+ Objek penelitian\n",
            "\n",
            "The proposal should not exceed 20 pages, excluding attachments.\n"
          ]
        }
      ],
      "source": [
        "input_message = \"Bagaimana format proposal skripsi?\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GgisUwwORYr",
        "outputId": "f0583501-3bd8-4cd5-8a68-c96cf8e2334e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "kalo format daftar pustaka?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (call_crjd)\n",
            " Call ID: call_crjd\n",
            "  Args:\n",
            "    query: kalo format daftar pustaka\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'page': 41.0, 'page_label': '42', 'source': './Pedoman_Skripsi_2024-rev.pdf'}\n",
            "Content: JURUSAN TEKNIK INFORMATIKA DAN KOMPUTER \n",
            "| PNJ 38 \n",
            " \n",
            "DAFTAR PUSTAKA \n",
            "Daftar pustaka berisi informasi tentang sumber pustaka yang telah dirujuk dalam tubuh tulisan. Setiap \n",
            "pustaka yang dirujuk dalam naskah harus muncul dalam daftar pustaka, begitu juga sebaliknya, setiap \n",
            "pustaka yang muncul dalam daftar pustaka harus pernah dirujuk dalam tubuh tulisan. \n",
            "Daftar pustaka ditulis mengacu kepada Harvard Style. Sumber pustaka diharapkan berasal dari sumber \n",
            "yang dapat dipertanggungjawabkan keabsahan ilmiahnya (misalnya jurnal ilmiah, buku teks, prosiding \n",
            "seminar dan lain-lain) dan bukan berasal dari opini pribadi yang dipublikasikan di internet atau media \n",
            "lainnya. Ketentuan Umum Penulisan Daftar Pustaka : \n",
            "a. Daftar pustaka disusun menurut urutan abjad nama belakang penulis pertama. Daftar \n",
            "pustaka ditulis dalam spasi 1.15. Antara satu pustaka dan pustaka berikutnya diberi jarak \n",
            "1,5 spasi. Baris pertama rata kiri dan baris berikutnya menjorok ke dalam (Harvard style).\n",
            "\n",
            "Source: {'page': 41.0, 'page_label': '42', 'source': './Pedoman_Skripsi_2024-rev.pdf'}\n",
            "Content: Penulisan : Sidney, Philip. \n",
            "Nama : Arthur George Rust Jr.   Penulisan : Rust, Arthur George, Jr. \n",
            "Nama : John D. Rockfeller IV. Penulisan : Rockfeller, John. D., IV \n",
            "d. Gelar kebangsawanan, akademik, dan keagamaan tidak perlu ditulis. \n",
            "e. Jika tidak ada nama penulis, judul karya dituliskan sebagai tema utama. \n",
            "f. Pada format Harvard huruf kapital digunakan pada setiap awal kata dari judul karya \n",
            "(kecuali kata sandang). \n",
            "g. Baris kedua setiap sumber ditulis dengan jarak 5 ketuk/spasi dari margin kir ibaris \n",
            "pertama dengan jarak antar baris 1.15 spasi. \n",
            "h. Daftar diurutkan berdasarkan abjad nama keluarga/nama belakang dengan jarak 1,5 \n",
            "spasi. \n",
            "i. Untuk daftar pustaka online (dari website) harus berupa tulisan ilmiah yang \n",
            "dipublikasikan secara ilmiah, tidak boleh berasal dari blog (curhat pribadi), facebook, \n",
            "Wikipedia.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Format daftar pustaka menurut Pedoman Skripsi 2024 adalah berdasarkan Harvard Style, dengan ketentuan sebagai berikut:\n",
            "\n",
            "* Susunan menurut urutan abjad nama belakang penulis pertama\n",
            "* Ditulis dalam spasi 1.15\n",
            "* Antara satu pustaka dan pustaka berikutnya diberi jarak 1,5 spasi\n",
            "* Baris pertama rata kiri dan baris berikutnya menjorok ke dalam\n",
            "* Gelar kebangsawanan, akademik, dan keagamaan tidak perlu ditulis\n",
            "* Jika tidak ada nama penulis, judul karya dituliskan sebagai tema utama\n",
            "* Pada format Harvard, huruf kapital digunakan pada setiap awal kata dari judul karya (kecuali kata sandang)\n",
            "* Baris kedua setiap sumber ditulis dengan jarak 5 ketuk/spasi dari margin kiri baris pertama dengan jarak antar baris 1.15 spasi\n",
            "* Daftar diurutkan berdasarkan abjad nama keluarga/nama belakang dengan jarak 1,5 spasi\n",
            "* Untuk daftar pustaka online (dari website) harus berupa tulisan ilmiah yang dipublikasikan secara ilmiah, tidak boleh berasal dari blog (curhat pribadi), facebook, Wikipedia.\n"
          ]
        }
      ],
      "source": [
        "input_message = \"kalo format daftar pustaka?\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5TU-m2ROU3V",
        "outputId": "80e46d13-3fa1-461f-e980-e41a31fcfbee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "apa itu bahasa pemograman python?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Python adalah sebuah bahasa pemrograman yang diciptakan oleh Guido van Rossum pada tahun 1990-an. Bahasa pemrograman ini dikembangkan dengan tujuan untuk membuat kode yang mudah dibaca dan ditulis, serta efisien dalam pemrograman.\n",
            "\n",
            "Python adalah bahasa pemrograman high-level, yang berarti bahwa programmer tidak perlu mengatur detail-render detail rendah-level seperti pada bahasa pemrograman low-level. Python juga memiliki sintaks yang lebih sederhana dan lebih mudah dibaca daripada bahasa pemrograman lainnya.\n",
            "\n",
            "Python dapat digunakan untuk berbagai tujuan, seperti:\n",
            "\n",
            "* Membuat aplikasi web\n",
            "* Membuat aplikasi desktop\n",
            "* Membuat script batch\n",
            "* Membuat analisis data\n",
            "* Membuat machine learning\n",
            "* Membuat artificial intelligence\n",
            "\n",
            "Python juga memiliki banyak library dan framework yang dapat digunakan untuk berbagai tujuan, seperti:\n",
            "\n",
            "* NumPy dan Pandas untuk analisis data\n",
            "* Flask dan Django untuk membuat aplikasi web\n",
            "* Matplotlib dan Seaborn untuk membuat grafik\n",
            "* Scikit-learn untuk machine learning\n",
            "* TensorFlow untuk artificial intelligence\n",
            "\n",
            "Python juga sangat populer dan digunakan oleh banyak orang, termasuk developer, data scientist, dan researcher.\n"
          ]
        }
      ],
      "source": [
        "input_message = \"apa itu bahasa pemograman python?\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8otiZtP8O3Fh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
